# News Sentiment Analyser ğŸ“° ğŸ¤–

Analyse the political sentiment of news articles using AI, powered by Ollama and TensorFlow. This tool automatically fetches news from RSS feeds and determines if articles lean Left, Right, or Centre in their political perspective.

## Features ğŸŒŸ

- ğŸ”„ Real-time RSS feed processing
- ğŸ§  Local AI analysis using Ollama (Mistral model)
- ğŸ“Š Visual sentiment statistics
- ğŸš€ High-performance processing with Bun
- ğŸ’¾ Model caching for improved performance
- ğŸ“ˆ Beautiful console output with sentiment distribution

## How It Works ğŸ› ï¸

1. Fetches latest news from your chosen RSS feed
2. Uses Ollama (Mistral) to analyse political sentiment
3. Falls back to TensorFlow embeddings if Ollama is unavailable
4. Generates a visual summary of political leanings

Example output:
```
=========================
ğŸ“Š Analysis Summary
=========================
ğŸ“š Total Articles: 10
âœ… Successfully Processed: 9
âŒ Failed: 1

ğŸ“ˆ Sentiment Distribution:
  Left: ğŸŸ¦ğŸŸ¦ğŸŸ¦ (3)
  Right: ğŸŸ¥ğŸŸ¥ (2)
  Centre: â¬œâ¬œâ¬œâ¬œ (4)

ğŸ”„ Processing Method:
  Ollama: ğŸ¤–ğŸ¤–ğŸ¤–ğŸ¤–ğŸ¤– (5)
  Local: ğŸ§®ğŸ§®ğŸ§®ğŸ§® (4)

â±ï¸ Time Elapsed: 12.34s
=========================
```

## Quick Start with Docker ğŸ³

The easiest way to run the analyser is using Docker Compose:

```bash
docker-compose up --build
```

This will:
- ğŸ“¦ Set up all required dependencies
- ğŸ¤– Start Ollama with the Mistral model
- ğŸš€ Launch the sentiment analyser
- ğŸ“Š Begin processing the latest news

## Configuration Options âš™ï¸

Customise the behaviour using environment variables:

```bash
# Basic usage with custom RSS feed (default: BBC News feed)
RSS_FEED_URL=https://your-news-source.com/feed.xml docker-compose up

# Enable debug logging
LOG_LEVEL=debug docker-compose up

# Custom Ollama settings
OLLAMA_HOST=http://custom-host OLLAMA_PORT=11434 docker-compose up
```

## Manual Setup ğŸ”§

If you prefer to run without Docker, you'll need:

1. Prerequisites:
   - [Bun](https://bun.sh) installed
   - [Ollama](https://ollama.ai) running locally
   - Node.js 18+ (for TensorFlow)

2. Installation:
   ```bash
   # Clone the repository
   git clone https://github.com/milesburton/news-sentiment-reader.git
   cd news-sentiment-reader

   # Install dependencies
   bun install

   # Run the analyser
   bun run start
   ```

## Project Structure ğŸ“

```
src/
  â”œâ”€â”€ types/          # TypeScript type definitions
  â”œâ”€â”€ utils/          # Utility functions and logger
  â”œâ”€â”€ download-model  # TensorFlow model management
  â”œâ”€â”€ fetchNews      # RSS feed handling
  â”œâ”€â”€ scrapeContent  # Article content extraction
  â””â”€â”€ main           # Application entry point
```

## Error Handling ğŸ”§

The analyser is designed to be resilient:
- âœ… Automatic fallback to TensorFlow if Ollama is unavailable
- ğŸ”„ Continues processing even if some articles fail
- ğŸ“ Detailed logging of any issues
- ğŸ›¡ï¸ Graceful handling of network errors

## Contributing ğŸ¤

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch:
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. Commit your changes:
   ```bash
   git commit -m 'feat: Add amazing feature'
   ```
4. Push to the branch:
   ```bash
   git push origin feature/amazing-feature
   ```
5. Open a Pull Request

## Troubleshooting ğŸ”

Common issues and solutions:

1. **Ollama Connection Failed**
   - Ensure Ollama is running
   - Check the OLLAMA_HOST and OLLAMA_PORT settings
   - The analyser will automatically fall back to TensorFlow

2. **RSS Feed Issues**
   - Verify the RSS_FEED_URL is accessible
   - Check your internet connection
   - Ensure the feed is properly formatted RSS

3. **Performance Issues**
   - Adjust LOG_LEVEL to reduce output
   - Ensure sufficient system resources
   - Check Docker resource allocation

## Licence ğŸ“„

[MIT](LICENSE)

## Acknowledgements ğŸ™

- Ollama team for the local AI capabilities
- TensorFlow.js team for the embeddings model
- Bun team for the high-performance runtime